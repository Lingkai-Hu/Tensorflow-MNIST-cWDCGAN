{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist= input_data.read_data_sets(\"D:/HLK/mydata/try/MNIST_data/\", one_hot=True,reshape=False)\n",
    "# mnist= input_data.read_data_sets(\"D:/BaiduNetdiskDownload/DAF/Fashion-MNIST/\", one_hot=True,reshape=False)\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.layers.python.layers import batch_norm\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training=tf.concat(False,1)\n",
    "def bnconv(x,filters,kernel_size=[3,3],strides=1,is_training=is_training, padding='same'):\n",
    "    with tf.name_scope('bnconv'):\n",
    "        x=tf.layers.conv2d(x,filters,kernel_size=kernel_size, strides=(strides, strides), padding=padding,use_bias=True)\n",
    "        x=batch_norm(x,decay=0.99,updates_collections=None,is_training=is_training,activation_fn=tf.nn.leaky_relu)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Autoencoders(image):\n",
    "    reuse=len([t for t in tf.global_variables() if t.name.startswith('Autoencoders')])>0\n",
    "    with tf.variable_scope('Autoencoders',reuse=reuse):\n",
    "        x=bnconv(image,64,[5,5])\n",
    "        x=bnconv(x,64,[5,5])\n",
    "        x=bnconv(x,64,[5,5],strides=2)\n",
    "        x=bnconv(x,64,[5,5])\n",
    "        x=bnconv(x,64,[5,5])\n",
    "        x=bnconv(x,128,[5,5],strides=2)\n",
    "        x=bnconv(x,128,[5,5])\n",
    "        x=bnconv(x,64,[5,5])\n",
    "        x=tf.layers.conv2d(x,32,kernel_size=[7,7],strides=(1, 1), padding='valid')\n",
    "        x=tf.reshape(x,[-1,16,2])\n",
    "        x=tf.nn.softmax(x,-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None, 28,28,1])\n",
    "x1 = tf.placeholder(tf.float32,[None, 28,28,1])\n",
    "y=Autoencoders(x)\n",
    "y1=Autoencoders(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vars=tf.trainable_variables()\n",
    "d_clip = [tf.assign(var, tf.clip_by_value(var, -0.01, 0.01)) for var in t_vars]\n",
    "\n",
    "tf.summary.histogram('y',y)\n",
    "loss=tf.reduce_mean(tf.abs(tf.abs(y1-y)-0.382))\n",
    "# loss=0.5*tf.log(loss)+0.5*tf.log(1-loss)\n",
    "tf.summary.scalar('loss',loss)\n",
    "\n",
    "train=tf.train.RMSPropOptimizer(0.0001).minimize(loss)\n",
    "# train=tf.train.AdamOptimizer(0.001).minimize(-loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "merged=tf.summary.merge_all()\n",
    "writer=tf.summary.FileWriter(r\"D:\\HLK\\jupyter_notebook\\GAN\\result\\A\\1\",sess.graph)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(40001)):\n",
    "    batch_xs1, batch_ys = mnist.train.next_batch(64)\n",
    "    batch_xs2, batch_ys = mnist.train.next_batch(64)\n",
    "    sess.run(train,{x:batch_xs1,x1:batch_xs2,is_training:True})\n",
    "    if i%50==0:\n",
    "        result=sess.run(merged,feed_dict={x:batch_xs1,x1:batch_xs2})\n",
    "        writer.add_summary(result,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=D:\\HLK\\jupyter_notebook\\GAN\\result\\A\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
